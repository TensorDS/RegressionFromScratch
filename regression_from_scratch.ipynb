{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression from Scratch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Daniel Wiesenfeld*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I demostrate how to fit a multiple linear regression and duplicate every metric in `statsmodels`' linear regression summary output from scratch*. By that, I mean using only Python with the `numpy` librarby, and for certain metrics I also needed the `scipy` library. I have also created an accompanying Google Sheet and Excel Workbook that computes all the metrics (except one) using built-in formulas only - no plugins, no add-ons, no custom code. Though this exercise is mostly for the fun of it (and to learn how all the formulas work), there are actually practical uses. I think you will find that it is far simpler and easier to generate $\\hat{\\beta}$'s with just `numpy`, which you will almost always use anyway in a data science context, than it is using `sklearn` or `statsmodels`. Also, many businesses use spreadsheets all the time. I can think of many instances where having that functionality within a spreadsheet, without the need for plugins, add-ons, or custom programming can be very helpful.\n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresher on Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are already an expert on multiple linear regression, feel fre to skip this part. If not, or if you're just a bit rusty, keep reading.\n",
    "\n",
    "Multiple Linear Regression is a model that finds a linear function of a set of features $X$ that estimates $y$. The feature matrix $X$ has $n$ rows, one per observation, and $p$ columns, one per feature. The target vector $y$ has $n$ elements, one per observation. In the field of machine learning, the terms features and target are often used, while in the field of statistics, $X$ and $y$ are often called, independent variables and the dependent variable, or exogenous variables and endogenous variable. Regardless, the meaning stays the same. \n",
    "\n",
    "Multiple Linear Regression differs from Simple Linear Regression in that there can be more than one column or feature in $X$. In simple linear regression, $X$ is just a vector of $n$ elements, and the regression function can be thought of as a line geometrically. the two coefficients, $\\beta_0$ and $\\beta_1$, are the y-intercept and the slope of the line.\n",
    "\n",
    "When $X$ has two or more features (excluding the constant, which we'll get to later), it becomes Multiple Linear Regression. When there are strictly two columns, the regression function can be thought of as a plane geometrically. The first coefficient, $\\beta_0$, represents the y-intercept (the point on the y axis where the plane intersects it) and the next two coeficients, $\\beta_1$ and $beta_2$ represent the slopes of the plane with respect to $y$ in the $x_1$ and $x_2$ axes respectively. Once there are three or more features, it becomes a hyperplane which is extremely difficult to visualize in three dimensions, but the concepts remain the same.\n",
    "\n",
    "In order to fit the hyperplane, the algorithm finds the hyperplane that minimizes the sum of the square of the distances from each point to the hyperplane along the y axis. This is why the alogirthm is often referred to as \"least squares\". The implicit assumption is that our $y$ is a random variable that follows a very particular set of rules: It is a linear function of $X$ plus some normally distributed error that has a mean of 0 and a variance $\\sigma^2$. The greater the magnitude of a coefficent, the more of an effect that feature has on $y$, and the sign of the coefficient indicates whether the effect is positive or negative. The lower $\\sigma^2$ is, the more accurately the output of the linear function matches $y$.\n",
    "\n",
    "This function is often written in various mathematically equivalent ways. The first way uses subscripts to represent the dimensional elements:\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1x_{i,1} + \\beta_2x_{i,2} + \\ldots + \\beta_px_{i,p} + r_i \\sim \\mathcal{N}(0, \\sigma^2)\\quad\\forall\\; i \\in \\{1, \\ldots, n\\}$$\n",
    "\n",
    "*Note: Many notations use the letter e to represent the error term, but I prefer r (residuals) so that it isn't confused with the base of the natural logarithm*\n",
    "\n",
    "Another more concise approach uses summation over the features:\n",
    "\n",
    "$$y_i = \\beta_0 + \\sum_{j = 1}^p \\beta_jx_{i,j}+ r_i \\sim \\mathcal{N}(0, \\sigma^2)\\quad\\forall\\; i \\in \\{1, \\ldots, n\\}$$\n",
    "\n",
    "The most concise and technical notation puts the whole thing into vector form, but before we do that let's deal with that pesky $\\beta_0$ which ruins the pattern. All the other $\\beta$'s are multiplied by their corresponding $x$'s, but the $\\beta_0$ is all by itself. We can fix this with a simple mathematical trick. Anything times 1 is just itself. So, we can add a column to the beginning of $X$ (before the first column), that consists of just 1's. This new column is usually referred to as the \"constant\". Now we can rewrite the first version as:\n",
    "\n",
    "$$y_i = \\beta_0x_{i,0} + \\beta_1x_{i,1} + \\beta_2x_{i,2} + \\ldots + \\beta_px_{i,p} + r_i \\sim \\mathcal{N}(0, \\sigma^2)\\quad\\forall\\; i \\in \\{1, \\ldots, n\\}$$,\n",
    "\n",
    "or the second version as:\n",
    "\n",
    "$$y_i = \\sum_{j = 0}^p \\beta_jx_{i,j}+ r_i \\sim \\mathcal{N}(0, \\sigma^2)\\quad\\forall\\; i \\in \\{1, \\ldots, n\\}$$.\n",
    "\n",
    "That didn't change anything mathematically, because the zero'th column of $X$ is just list of $n$ 1's. So each $\\beta_0$ is just being multiplied by 1 and staying the same as before. It does however much more convenient to write in matrix form: \n",
    "\n",
    "$$y = X\\beta^\\top + r \\sim \\mathcal{N}(0, \\sigma^2)$$\n",
    "\n",
    "In the above notation, $X$ is an $n\\times p$ matrix (this new $p$ is one more than the previous $p$ because we added the constant), $\\beta$ is a $p$ length vector, and $y$ and $r$ are both $n$ length vectors.\n",
    "\n",
    "\n",
    "Now this function of $y$ is unknown. We don't know the true values of $\\beta$ and we don't no the true value of $\\sigma^2$. The least squares algorithm allows us to estimate those values. We commonly notate estimated values by putting little hats on them. So our estimated values would be $\\hat\\beta$ and $\\hat\\sigma^2$. It is also common to refer to $\\hat\\beta$ as $b$.\n",
    "\n",
    "Once we have our $b$ values, we can use them on any row of $x$ values to estimate a value for its corresponding $y$ value - which also gets a hat: $\\hat y$. When we do this with a previously unseen row or rows of $x$ values, those computed valeus of $\\hat y$ can be thought of as predicted values of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Imports and Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import our libraries and get the data in a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS, datasets, add_constant # we'll use this to get some data and to compare our results\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the macrodata dataset from `statsmodels` as our example. We will build a multiple regression model to predict unemployment with seven features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>realgdp</th>\n",
       "      <th>realcons</th>\n",
       "      <th>realinv</th>\n",
       "      <th>realgovt</th>\n",
       "      <th>realdpi</th>\n",
       "      <th>cpi</th>\n",
       "      <th>m1</th>\n",
       "      <th>tbilrate</th>\n",
       "      <th>unemp</th>\n",
       "      <th>pop</th>\n",
       "      <th>infl</th>\n",
       "      <th>realint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2710.349</td>\n",
       "      <td>1707.4</td>\n",
       "      <td>286.898</td>\n",
       "      <td>470.045</td>\n",
       "      <td>1886.9</td>\n",
       "      <td>28.98</td>\n",
       "      <td>139.7</td>\n",
       "      <td>2.82</td>\n",
       "      <td>5.8</td>\n",
       "      <td>177.146</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2778.801</td>\n",
       "      <td>1733.7</td>\n",
       "      <td>310.859</td>\n",
       "      <td>481.301</td>\n",
       "      <td>1919.7</td>\n",
       "      <td>29.15</td>\n",
       "      <td>141.7</td>\n",
       "      <td>3.08</td>\n",
       "      <td>5.1</td>\n",
       "      <td>177.830</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2775.488</td>\n",
       "      <td>1751.8</td>\n",
       "      <td>289.226</td>\n",
       "      <td>491.260</td>\n",
       "      <td>1916.4</td>\n",
       "      <td>29.35</td>\n",
       "      <td>140.5</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.3</td>\n",
       "      <td>178.657</td>\n",
       "      <td>2.74</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2785.204</td>\n",
       "      <td>1753.7</td>\n",
       "      <td>299.356</td>\n",
       "      <td>484.052</td>\n",
       "      <td>1931.3</td>\n",
       "      <td>29.37</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.6</td>\n",
       "      <td>179.386</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2847.699</td>\n",
       "      <td>1770.5</td>\n",
       "      <td>331.722</td>\n",
       "      <td>462.199</td>\n",
       "      <td>1955.5</td>\n",
       "      <td>29.54</td>\n",
       "      <td>139.6</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>180.007</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  quarter   realgdp  realcons  realinv  realgovt  realdpi    cpi  \\\n",
       "0  1959.0      1.0  2710.349    1707.4  286.898   470.045   1886.9  28.98   \n",
       "1  1959.0      2.0  2778.801    1733.7  310.859   481.301   1919.7  29.15   \n",
       "2  1959.0      3.0  2775.488    1751.8  289.226   491.260   1916.4  29.35   \n",
       "3  1959.0      4.0  2785.204    1753.7  299.356   484.052   1931.3  29.37   \n",
       "4  1960.0      1.0  2847.699    1770.5  331.722   462.199   1955.5  29.54   \n",
       "\n",
       "      m1  tbilrate  unemp      pop  infl  realint  \n",
       "0  139.7      2.82    5.8  177.146  0.00     0.00  \n",
       "1  141.7      3.08    5.1  177.830  2.34     0.74  \n",
       "2  140.5      3.82    5.3  178.657  2.74     1.09  \n",
       "3  140.0      4.33    5.6  179.386  0.27     4.06  \n",
       "4  139.6      3.50    5.2  180.007  2.31     1.19  "
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(datasets.macrodata.load().data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create our `X` dataframe, by selecting 7 features of interest and adding a constant, and we will select the 'unemp' column as our `y` series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>realgdp</th>\n",
       "      <th>realcons</th>\n",
       "      <th>realgovt</th>\n",
       "      <th>realdpi</th>\n",
       "      <th>cpi</th>\n",
       "      <th>m1</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2710.349</td>\n",
       "      <td>1707.4</td>\n",
       "      <td>470.045</td>\n",
       "      <td>1886.9</td>\n",
       "      <td>28.98</td>\n",
       "      <td>139.7</td>\n",
       "      <td>177.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2778.801</td>\n",
       "      <td>1733.7</td>\n",
       "      <td>481.301</td>\n",
       "      <td>1919.7</td>\n",
       "      <td>29.15</td>\n",
       "      <td>141.7</td>\n",
       "      <td>177.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2775.488</td>\n",
       "      <td>1751.8</td>\n",
       "      <td>491.260</td>\n",
       "      <td>1916.4</td>\n",
       "      <td>29.35</td>\n",
       "      <td>140.5</td>\n",
       "      <td>178.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2785.204</td>\n",
       "      <td>1753.7</td>\n",
       "      <td>484.052</td>\n",
       "      <td>1931.3</td>\n",
       "      <td>29.37</td>\n",
       "      <td>140.0</td>\n",
       "      <td>179.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2847.699</td>\n",
       "      <td>1770.5</td>\n",
       "      <td>462.199</td>\n",
       "      <td>1955.5</td>\n",
       "      <td>29.54</td>\n",
       "      <td>139.6</td>\n",
       "      <td>180.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const   realgdp  realcons  realgovt  realdpi    cpi     m1      pop\n",
       "0    1.0  2710.349    1707.4   470.045   1886.9  28.98  139.7  177.146\n",
       "1    1.0  2778.801    1733.7   481.301   1919.7  29.15  141.7  177.830\n",
       "2    1.0  2775.488    1751.8   491.260   1916.4  29.35  140.5  178.657\n",
       "3    1.0  2785.204    1753.7   484.052   1931.3  29.37  140.0  179.386\n",
       "4    1.0  2847.699    1770.5   462.199   1955.5  29.54  139.6  180.007"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['realgdp', 'realcons', 'realgovt', 'realdpi', 'cpi', 'm1', 'pop']].pipe(add_constant)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to be a stickler and say I can't use statsmodels to add the constant, just use this cell instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>realgdp</th>\n",
       "      <th>realcons</th>\n",
       "      <th>realgovt</th>\n",
       "      <th>realdpi</th>\n",
       "      <th>cpi</th>\n",
       "      <th>m1</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2710.349</td>\n",
       "      <td>1707.4</td>\n",
       "      <td>470.045</td>\n",
       "      <td>1886.9</td>\n",
       "      <td>28.98</td>\n",
       "      <td>139.7</td>\n",
       "      <td>177.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2778.801</td>\n",
       "      <td>1733.7</td>\n",
       "      <td>481.301</td>\n",
       "      <td>1919.7</td>\n",
       "      <td>29.15</td>\n",
       "      <td>141.7</td>\n",
       "      <td>177.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2775.488</td>\n",
       "      <td>1751.8</td>\n",
       "      <td>491.260</td>\n",
       "      <td>1916.4</td>\n",
       "      <td>29.35</td>\n",
       "      <td>140.5</td>\n",
       "      <td>178.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2785.204</td>\n",
       "      <td>1753.7</td>\n",
       "      <td>484.052</td>\n",
       "      <td>1931.3</td>\n",
       "      <td>29.37</td>\n",
       "      <td>140.0</td>\n",
       "      <td>179.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2847.699</td>\n",
       "      <td>1770.5</td>\n",
       "      <td>462.199</td>\n",
       "      <td>1955.5</td>\n",
       "      <td>29.54</td>\n",
       "      <td>139.6</td>\n",
       "      <td>180.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const   realgdp  realcons  realgovt  realdpi    cpi     m1      pop\n",
       "0    1.0  2710.349    1707.4   470.045   1886.9  28.98  139.7  177.146\n",
       "1    1.0  2778.801    1733.7   481.301   1919.7  29.15  141.7  177.830\n",
       "2    1.0  2775.488    1751.8   491.260   1916.4  29.35  140.5  178.657\n",
       "3    1.0  2785.204    1753.7   484.052   1931.3  29.37  140.0  179.386\n",
       "4    1.0  2847.699    1770.5   462.199   1955.5  29.54  139.6  180.007"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['realgdp', 'realcons', 'realgovt', 'realdpi', 'cpi', 'm1', 'pop']]\n",
    "X.insert(0, 'const', 1.0)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and let's create our y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.8\n",
       "1    5.1\n",
       "2    5.3\n",
       "3    5.6\n",
       "4    5.2\n",
       "Name: unemp, dtype: float64"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['unemp']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try out the Excel sheets on your own, run the following code if you want to copy X & y as a single dataframe to the clopboard so you can paste in Sheets or Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.assign(y = y).to_clipboard()\n",
    "# now just paste in Sheets or Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK let's take a look at what `statsmodels` gives us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>unemp</td>      <th>  R-squared:         </th> <td>   0.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   197.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 May 2023</td> <th>  Prob (F-statistic):</th> <td>6.21e-85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:27:02</td>     <th>  Log-Likelihood:    </th> <td> -151.94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   203</td>      <th>  AIC:               </th> <td>   319.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   195</td>      <th>  BIC:               </th> <td>   346.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>  -17.5391</td> <td>    2.806</td> <td>   -6.250</td> <td> 0.000</td> <td>  -23.074</td> <td>  -12.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realgdp</th>  <td>   -0.0116</td> <td>    0.000</td> <td>  -27.105</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realcons</th> <td>    0.0087</td> <td>    0.001</td> <td>   10.055</td> <td> 0.000</td> <td>    0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realgovt</th> <td>   -0.0030</td> <td>    0.001</td> <td>   -4.824</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realdpi</th>  <td>    0.0029</td> <td>    0.001</td> <td>    4.112</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cpi</th>      <td>    0.0799</td> <td>    0.006</td> <td>   13.065</td> <td> 0.000</td> <td>    0.068</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m1</th>       <td>   -0.0030</td> <td>    0.001</td> <td>   -4.945</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>      <td>    0.1907</td> <td>    0.018</td> <td>   10.646</td> <td> 0.000</td> <td>    0.155</td> <td>    0.226</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.415</td> <th>  Durbin-Watson:     </th> <td>   0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.813</td> <th>  Jarque-Bera (JB):  </th> <td>   0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.057</td> <th>  Prob(JB):          </th> <td>   0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.106</td> <th>  Cond. No.          </th> <td>8.61e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.61e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  unemp   R-squared:                       0.876\n",
       "Model:                            OLS   Adj. R-squared:                  0.872\n",
       "Method:                 Least Squares   F-statistic:                     197.6\n",
       "Date:                Thu, 18 May 2023   Prob (F-statistic):           6.21e-85\n",
       "Time:                        17:27:02   Log-Likelihood:                -151.94\n",
       "No. Observations:                 203   AIC:                             319.9\n",
       "Df Residuals:                     195   BIC:                             346.4\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -17.5391      2.806     -6.250      0.000     -23.074     -12.004\n",
       "realgdp       -0.0116      0.000    -27.105      0.000      -0.012      -0.011\n",
       "realcons       0.0087      0.001     10.055      0.000       0.007       0.010\n",
       "realgovt      -0.0030      0.001     -4.824      0.000      -0.004      -0.002\n",
       "realdpi        0.0029      0.001      4.112      0.000       0.002       0.004\n",
       "cpi            0.0799      0.006     13.065      0.000       0.068       0.092\n",
       "m1            -0.0030      0.001     -4.945      0.000      -0.004      -0.002\n",
       "pop            0.1907      0.018     10.646      0.000       0.155       0.226\n",
       "==============================================================================\n",
       "Omnibus:                        0.415   Durbin-Watson:                   0.779\n",
       "Prob(Omnibus):                  0.813   Jarque-Bera (JB):                0.204\n",
       "Skew:                           0.057   Prob(JB):                        0.903\n",
       "Kurtosis:                       3.106   Cond. No.                     8.61e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.61e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = OLS(y, X)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with `statsmodels` output is that the numbers are all rounded to no more than three decimal places. It will be hard to see how accurate our own computations are unless we extract these attributes independently from the `res` object. I show you how to do it below and conveniently save them in variables beginning with the suffix '_sm', so that we can compare them to our own computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764203251692085"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_sm = res.rsquared # R-squared\n",
    "r2_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719841317137442"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_adj_sm = res.rsquared_adj # Adj. R-squared\n",
    "r2_adj_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.56134036257416"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_sm = res.fvalue # F-Statistic\n",
    "f_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.214397666559647e-85"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_f_sm = res.f_pvalue # Prob(F-Statistic)\n",
    "p_f_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-151.94432883403306"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_sm = res.llf # Log-Likelihood\n",
    "l_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319.8886576680661"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic_sm = res.aic # AIC\n",
    "aic_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346.39430550040043"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic_sm = res.bic # BIC\n",
    "bic_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -17.539104\n",
       "realgdp     -0.011650\n",
       "realcons     0.008694\n",
       "realgovt    -0.003007\n",
       "realdpi      0.002923\n",
       "cpi          0.079861\n",
       "m1          -0.003043\n",
       "pop          0.190674\n",
       "dtype: float64"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_sm = res.params # coefficients\n",
    "b_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const       2.806322\n",
       "realgdp     0.000430\n",
       "realcons    0.000865\n",
       "realgovt    0.000623\n",
       "realdpi     0.000711\n",
       "cpi         0.006113\n",
       "m1          0.000615\n",
       "pop         0.017910\n",
       "dtype: float64"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_sm = res.bse # standard erros of coefficients\n",
    "s_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const       -6.249854\n",
       "realgdp    -27.105072\n",
       "realcons    10.054683\n",
       "realgovt    -4.824153\n",
       "realdpi      4.112236\n",
       "cpi         13.064576\n",
       "m1          -4.944581\n",
       "pop         10.646391\n",
       "dtype: float64"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sm = res.tvalues # t values of coefficients\n",
    "t_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const       2.532927e-09\n",
       "realgdp     4.704738e-68\n",
       "realcons    1.991447e-19\n",
       "realgovt    2.828657e-06\n",
       "realdpi     5.772642e-05\n",
       "cpi         1.972339e-28\n",
       "m1          1.641259e-06\n",
       "pop         3.691092e-21\n",
       "dtype: float64"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_sm = res.pvalues # p values of coefficients\n",
    "p_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -23.073744\n",
       "realgdp     -0.012497\n",
       "realcons     0.006989\n",
       "realgovt    -0.004236\n",
       "realdpi      0.001521\n",
       "cpi          0.067805\n",
       "m1          -0.004256\n",
       "pop          0.155352\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_sm = res.conf_int()[0] # lower bound of 95% confidence interval of coefficients\n",
    "lb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -12.004463\n",
       "realgdp     -0.010802\n",
       "realcons     0.010399\n",
       "realgovt    -0.001777\n",
       "realdpi      0.004325\n",
       "cpi          0.091916\n",
       "m1          -0.001829\n",
       "pop          0.225995\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub_sm = res.conf_int()[1] # upper bound of 95% confidence interval of coefficients\n",
    "ub_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottom-most table of the summary output requires a few more methods from `statsmodels` and access to the model's residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import omni_normtest, robust_skewness, robust_kurtosis, durbin_watson, jarque_bera\n",
    "resid_sm = res.resid # residuals (errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41478658948228114"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omni_sm = omni_normtest(resids_sm)[0] # Omnibus statistic of residuals\n",
    "omni_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126999565057904"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_omni_sm = omni_normtest(resids_sm)[1] # Prob(Omnibus)\n",
    "p_omni_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056667302727931364"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew_sm = robust_skewness(resids)[0] # Skewness of residuals\n",
    "skew_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1061908834830367"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurt_sm = robust_kurtosis(resids)[0] + 3 # Kurtosis of residuals\n",
    "kurt_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778964211500831"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_sm = durbin_watson(resids) # Durbin-Watson\n",
    "dw_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20402545897229157"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb_sm = jarque_bera(resids)[0] # Jarque-Bera (JB)\n",
    "jb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9030180566398727"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_jb_sm = jarque_bera(resids)[1] # Prob(JB)\n",
    "p_jb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860663.3059185082"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_sm = res.condition_number #Cond. No.\n",
    "cn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the Metrics from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the most important metrics, the coefficients themselves!\n",
    "Multiple Linear Regression is actually just a linear algebra problem. Pro tip: the `@` operator is a shortcut form matrix multiplication. In multiple linear regression, we assume that  $ y = \\beta^\\top X + e$, where $e$ is an n - length vector of in which each $e_i$ is a normally distributed random variable with mean $0$ and variance $\\sigma^2$. We don't know the true value of $\\beta$, but we can estimate $\\hat{\\beta}$ or $b$ for short as:\n",
    "\n",
    "$$b = (X^\\top X)^{-1}X^\\top y $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -17.539104\n",
       "realgdp     -0.011650\n",
       "realcons     0.008694\n",
       "realgovt    -0.003007\n",
       "realdpi      0.002923\n",
       "cpi          0.079861\n",
       "m1          -0.003043\n",
       "pop          0.190674\n",
       "dtype: float64"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "b.index = X.columns #reindexing with column names makes it easier to see!\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! let's compare them to the coefficients we pulled from `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -2.014140e-10\n",
       "realgdp    -1.008395e-14\n",
       "realcons    9.141299e-14\n",
       "realgovt    2.271707e-14\n",
       "realdpi    -9.579967e-14\n",
       "cpi         1.537936e-13\n",
       "m1         -1.881134e-14\n",
       "pop         1.316003e-12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b - b_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we're off by a teeny tiny fraction ... most likely due to rounding differences between `statsmodels` and `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard errors are a bit more involved, so let's jump up to the top table of the summary and compute some things there first, as some of them will come in handy later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Top Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top table contains information pertaining to the entire model. We won't bother computing things like dependent variable name, model type, date, and time because those are trivial and obvious, but we'll compute everything else. \n",
    "\n",
    "We'll start with the three values in the first colum, the number of observations and the two degrees of freedom.\n",
    "\n",
    "*Note: the covariance type is always non-robust by default and our computations assume a non-robust covariance, so we will not get into that either.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of observations is simply the number of rows in X or the length of y, which we'll call n.\n",
    "n = len(y)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 7)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The degress of freedom of the residuals is n less the number of parameters of the model,\n",
    "# and the degrees of freedom of the model is the number of parameters of the model - 1.\n",
    "\n",
    "# We'll start by creating p as the parameters of the model, which is just the columns in X, and then compute the two df's.\n",
    "# These degrees of freedoms are used in various other metrics. The variable p will come in handy later.\n",
    "\n",
    "p = X.shape[1]\n",
    "dfr = n - p\n",
    "dfm = p - 1\n",
    "dfr, dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute R-squared. R-squared tells us how well $X$ explains $y$. It ranges from 0, no explanatory power, to 1, full explanatory power. It is computed as: \n",
    "$$R^2 = 1 - \\frac{\\text{SSE}}{\\text{SST}}$$\n",
    "\n",
    "\n",
    "SSE or sum of squares of errors is the sum of the squares of each residual (error) $r_i$ - the difference between each true value $y_i$ and its predicted value $\\hat{y_i}$:\n",
    "$$ \\text{SSE} = \\sum_{i=1}^n r_i^2 = \\sum_{i=1}^n (y_i - \\hat{y_i})^2 $$\n",
    "\n",
    "\n",
    "SST or the sum of total squares is the sum of the squares of of the differences between each $y_i$ and $\\bar{y}$ (the average of all $y_i$'s):\n",
    "\n",
    "$$ \\text{SST} = \\sum_{i=1}^n (y_i - \\bar{y})^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764203251692086"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's compute all the things we'll need and the R-squared itself.\n",
    "\n",
    "yhat = X @ np.array(beta).T # for whatever reason, we need to first recast the beta series as an array before the matrix mult\n",
    "resid = y - yhat\n",
    "sse = (resid**2).sum()\n",
    "ybar = y.mean()\n",
    "sst = ((y - ybar)**2).sum()\n",
    "r2 = 1 - sse/sst\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1102230246251565e-16"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "r2 - r2_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted R-squared is just a version of R squared that is penalized for having additional parameters. As you can see for a two-parameter model (i.e. simple linear regression), it reduces to R-squared:\n",
    "\n",
    "$$ R^2_{\\text{adj.}} = 1 - \\frac{\\text{SSE}}{\\text{SST}}\\left(\\frac{n - 1}{n-p-1}\\right) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713242561040214"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_adj = 1 - (sse/sst) * (n - 1)/(n - p - 1)\n",
    "r2_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F test measures the probability that at least one independent variable (excluding the constant) makes the model more predictive than not having any of the independent variables. Essentially, it's the probability that our model beats the baseline estimator $\\bar{y}$. The greater the F-statistic, the better our model. Our null hypothesis is that our model is no better than $\\bar{y}$. In order to put a probability to that, we take the area under the right tail of the F distribution (i.e. where x > F-stat) with the degrees of freedom we computed above. That value is the probability of incorrectly rejecting the null hypothesis (i.e. believing that our model beats the baseline when it actually doesn't). You can also thinkg of is as the probability that we would see results as extreme or more extreme than our model results by chance even if there was in reality no relationship between the independent variables and $y$. The smaller the p-value, the more confident we can be in our model. \n",
    "\n",
    "The F-Statistic is computed as:\n",
    "\n",
    "$$\\text{F-statistic} = \\frac{\\text{MSM}}{\\text{MSE}} \\sim \\mathcal{F}(\\text{df}_{\\text{residual}},\\text{df}_{\\text{model}} )$$\n",
    "\n",
    "The denominator of that, the MSE, is the mean version of hte SSE we computed above and is computed as: \n",
    "$$ \\text{MSE} = \\frac{\\text{SSE}}{\\text{df}_{\\text{residual}}}$$,\n",
    "and if you recall $\\text{df}_{\\text{residual}} = n-p$.\n",
    "\n",
    "The numerator, the MSM, is the mean version of the SSM, sum of squares model, which we have not yet computed. The SSM is the sum of the squares of the differences between each $\\hat{y_i}$ and $\\bar{y}$. You can think of it as how much we gain from the model vs. our baseline guess. If we didn't have our model, and we just had all the values of $y$, if we had to guess the value of a randomly drawn $y_i$, our best guess would be the mean, $\\bar{y}$:\n",
    "$$\\text{SSM} =\\sum_{i=1}^n (\\hat{y_i} - \\bar{y})^2 $$\n",
    "\n",
    "(Note that $\\text{SST} = \\text{SSE} + \\text{SSM}$)\n",
    "\n",
    "MSM is then computed as:\n",
    "$$ \\text{MSM} = \\frac{\\text{SSM}}{\\text{df}_{\\text{model}}} $$,\n",
    "and if you recall, $\\text{df}_{\\text{model}} = p-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.5613403619848"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm = ((yhat - ybar)**2).sum()\n",
    "msm = ssm / dfm\n",
    "\n",
    "mse = sse / dfr\n",
    "f = msm / mse\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.893525667488575e-10"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "f - f_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the p-value of the F statistic using the F distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.214397668138137e-85"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_f = sp.stats.f.sf(f, dfm, dfr)\n",
    "p_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.57849073308343e-94"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "p_f - p_f_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Log-Likelihood is a measure of how likely the coefficients estimates in our model are the *true* coefficients. Multiple regression assumption assumes that: $ y = \\beta^\\top X + r \\sim \\mathcal{N}(0, \\sigma^2)$, where $r$ is an n - length vector in which each $r_i$ is a normally distributed random variable with mean $0$ and variance $\\sigma^2$. We don't know the true coeffiecients $\\beta$ or $\\sigma^2$ of this  function, but the multiple regression algorithm allows us to estimate $\\beta$ as $\\hat{\\beta}=b$ and estimate $\\sigma$ as $\\hat{\\sigma}=mse$.\n",
    "\n",
    "The Likelihood $\\mathcal{L}$, represents the likelihood that our estimates are correct. It is the product of the value of the pdf of the Normal distribution evaluated at each observation of our training set using our estimated values. However, for mathematical convenience, we usually use the Log-Likelihood $\\mathcal{l}$, which is equivalent to the sum of the log of the pdf of the Normal Distribution evaluated at each observation of our training set using our estimated parameters (because the log of a product is equivalent to the sum of logs - $\\log(\\Pi x_i) = \\Sigma \\log(x_i)$). While the full formula is complex, in the case of multiple regression, it reduces to relatively simple formula:\n",
    "\n",
    "$$ \\text{Log-Likelihood} = \\mathcal{l} = \\frac{n}{2}\\left(\\log(n) - \\log(2\\pi\\: \\text{SSE}) - 1\\right) $$\n",
    "\n",
    "The Log-Likelihood can take any real value from $-\\infty$ to $+\\infty$ - though in practice it will usually be negative. The greater the Log-Likelihood, the more confident we can be in our parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-151.944328834033"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = n/2 * (np.log(n) - np.log(2 * np.pi * sse) - 1)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.684341886080802e-14"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "l - l_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) both measure information gain by the model while penalize extra parameters (higher number is better).\n",
    "\n",
    "$$\\text{AIC} = 2p - 2\\mathcal{l} $$\n",
    "$$\\text{BIC} = p\\log(n) - 2\\mathcal{l}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319.888657668066"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic = 2 * p - 2 * ll\n",
    "aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1368683772161603e-13"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "aic - aic_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346.3943055004003"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic = p * np.log(n) - 2 * ll\n",
    "bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1368683772161603e-13"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "bic - bic_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's return to the middle table of the summary, the coefficeint table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Standard Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each exogenous variable has a true, unknown $\\beta_j$, so we estimated $b_j$ as our best guess. We did this many steps ago with the formula:\n",
    "\n",
    "$$b = (X^\\top X)^{-1}X^\\top y$$,\n",
    "\n",
    "which represents the estimated expected value of $\\beta$, now we need to compute the standard error of each $b_j$ which is a measure of the expected deviation from the expectation (like a standard deviation), which gives us a sense of how confident we are in the coeficient estimate.\n",
    "\n",
    "To do that we take the square root of the product of the MSE we computed above and each $b_j$'s corresponding diagonal element of $(X^\\top X)^{-1}$ (the element at the $j$th row and $j$th column).\n",
    "\n",
    "$$\\text{standard error}_j = s_j = \\sqrt{\\text{MSE}\\times(X^\\top X)^{-1}_{jj}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const       2.806322\n",
       "realgdp     0.000430\n",
       "realcons    0.000865\n",
       "realgovt    0.000623\n",
       "realdpi     0.000711\n",
       "cpi         0.006113\n",
       "m1          0.000615\n",
       "pop         0.017910\n",
       "Name: s, dtype: float64"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.sqrt(mse * np.diag(np.linalg.inv(X.T @ X)))\n",
    "s = pd.Series(name = 's', data = s, index = X.columns) #reindexing with column names makes it easier to see!\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -3.210765e-13\n",
       "realgdp     9.164761e-16\n",
       "realcons    3.199047e-15\n",
       "realgovt   -1.128654e-16\n",
       "realdpi     1.051568e-15\n",
       "cpi         1.607221e-15\n",
       "m1          7.697835e-17\n",
       "pop         7.719519e-15\n",
       "dtype: float64"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "s - s_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The T-value, is the ratio between the coefficient and its standard error. \n",
    "$$ T = \\frac{b}{se} \\sim \\mathcal{t}_{\\text{df}_{\\text{residual}}} $$\n",
    "\n",
    "We then use each one to determine the probability that the we will incorrectly reject the null hypothesis. That is, the probability that the coefficient is, in reality 0. This is eqivalent to a draw from Student's $t$ distribution with df$_{residual}$ degrees of freedom that has a magnitude greater than that of the T value's magnitude. In other words, the probability that a draw from the distribution is greather than the absolute value of the T value or less than the negation of the absolute value of the T value. This is known as a two-tailed test. The smaller the p value for a coefficient, the more confident we can be that the true value of the coefficient is not 0.\n",
    "$$ p = \\mathbb{P}\\left[(x \\sim t_{\\text{df}_{residual}} < - |T|) \\cup (x \\sim t_{\\text{df}_{residual}} > |T|)\\right] $$\n",
    "\n",
    "We can also determine the confidence interval around the coefficient for any significance $1 - \\alpha$ (95% by default) by using the critical value of the t distribution that leaves $\\alpha/2$ probability mass in each tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const       -6.249854\n",
       "realgdp    -27.105072\n",
       "realcons    10.054683\n",
       "realgovt    -4.824153\n",
       "realdpi      4.112236\n",
       "cpi         13.064576\n",
       "m1          -4.944581\n",
       "pop         10.646391\n",
       "dtype: float64"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = b/se\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -7.248691e-11\n",
       "realgdp     3.433342e-11\n",
       "realcons    6.852119e-11\n",
       "realgovt    3.557599e-11\n",
       "realdpi    -1.408402e-10\n",
       "cpi         2.172307e-11\n",
       "m1         -2.995115e-11\n",
       "pop         6.889067e-11\n",
       "dtype: float64"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "t - t_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const       2.532927e-09\n",
       "realgdp     4.704738e-68\n",
       "realcons    1.991447e-19\n",
       "realgovt    2.828657e-06\n",
       "realdpi     5.772642e-05\n",
       "cpi         1.972339e-28\n",
       "m1          1.641259e-06\n",
       "pop         3.691092e-21\n",
       "dtype: float64"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = t.apply(lambda x: sp.stats.t.sf(abs(x), dfr)*2)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -9.791399e-19\n",
       "realgdp     9.194666e-78\n",
       "realcons   -9.122227e-29\n",
       "realgovt    4.508604e-16\n",
       "realdpi     3.240156e-14\n",
       "cpi        -3.002023e-38\n",
       "m1         -2.241380e-16\n",
       "pop        -1.726683e-30\n",
       "dtype: float64"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "p - p_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -23.073744\n",
       "realgdp     -0.012497\n",
       "realcons     0.006989\n",
       "realgovt    -0.004236\n",
       "realdpi      0.001521\n",
       "cpi          0.067805\n",
       "m1          -0.004256\n",
       "pop          0.155352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance = .95\n",
    "alpha = 1 - significance\n",
    "t_critical = sp.stats.t.isf(alpha/2, dfr)\n",
    "lb = b - t_critical * se\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -2.007816e-10\n",
       "realgdp    -1.189153e-14\n",
       "realcons    8.510380e-14\n",
       "realgovt    2.293998e-14\n",
       "realdpi    -9.787375e-14\n",
       "cpi         1.506295e-13\n",
       "m1         -1.896400e-14\n",
       "pop         1.300765e-12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "lb - lb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -12.004463\n",
       "realgdp     -0.010802\n",
       "realcons     0.010399\n",
       "realgovt    -0.001777\n",
       "realdpi      0.004325\n",
       "cpi          0.091916\n",
       "m1          -0.001829\n",
       "pop          0.225995\n",
       "dtype: float64"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub = b + t_critical * se\n",
    "ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const      -2.020464e-10\n",
       "realgdp    -8.276366e-15\n",
       "realcons    9.772218e-14\n",
       "realgovt    2.249438e-14\n",
       "realdpi    -9.372537e-14\n",
       "cpi         1.569578e-13\n",
       "m1         -1.865934e-14\n",
       "pop         1.331241e-12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "ub - ub_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that wraps up the middle table of the summary, let's move on to the final table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Final Table (Residual Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final table is mostly focused on statistics related to the residuals (errors). These are diagnostics to measure the degree to which the errors are normally distributed and heteroskedastic. There is also a statistic focused on multicollinearity of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the Skewness and Kurtosis. The Skewness is the third moment of a distrubution and measures its asymetry around the mean. A normal distrubution is perfectly symetric and has a skewness of 0. A positively skewed distribution has a longer right tail and its mean is greater than its median. A negatively skewed distribution has a longer left tail and its mean is less than its median.\n",
    "\n",
    "$$\\text{Skewness}_{residual} = \\frac{\\sum_{i = 1}^n r_i^3}{n \\sigma_r^3}$$,\n",
    "\n",
    "where $r$ is the vector of residuals and $\\sigma_r$ is its standard deviation.\n",
    "\n",
    "Kurtosis is the fourth moment of a distribution and measures its \"spikiness\" or \"heaviness\". A Normal distribution has a kurtosis of 3, so some versions subtract 3 from the kurtosis so that the normal baseline would be 0 and call that value \"excess kurtosis\". Sometimes excess kurtosis is just referred to as kurtoses, so it is important to know which version you are using. A normal distribution is knowns as mesokurtic. When kurtosis increases, the distribution becomes leptokurtic, meaning probability mass shifts into the tails, so the center of the distribution becomes thinner and taller. When the he kurtosis decreases the distribution becomes platykurtic, meaning the probability mass shifts toward the mean so the center becomes wider and shorter.\n",
    "\n",
    "\n",
    "$$\\text{Kurtosis}_{residual} = \\frac{\\sum_{i = 1}^n r_i^4}{n \\sigma_r^4}$$,\n",
    "\n",
    "where $r$ is the vector of residuals and $\\sigma_r$ is its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056667302773462505"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew = sum(resid**3)/(n * np.std(resid)**3)\n",
    "skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5531141357191274e-11"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "skew - skew_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.106190883487652"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurt = sum(resid**4)/(n * np.std(resid)**4)\n",
    "kurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.615419157971701e-12"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "kurt - kurt_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the assumptions of linear regression is that the residuals are normally distributed. We the following two tests use the skewness and kurtosis of the residuals to measaure the probability that the residuals are actuall normally distributed. In each case the null hypothesis is that the skewness and excess kurtosis are both 0. The p value for each represents the probability of incorrectly rejecting the null hypothesis - that is assuming that the residuals are not normally distributed when in fact they are. Therefore, unlike the previous p-values, we are looking for high p-values here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first test is the Omnibus (also known as the D'Agostiono- Pearson) statistic. \n",
    "\n",
    "$$\\text{Omnibus} = Z_s(\\text{skewness})^2 + Z_k(\\text{kurtosis})^2 \\sim \\chi^2_2$$\n",
    "\n",
    "The $Z$ transoformations make the skewness and kurtoses normally distributed and are a bit involved to compute. I credit https://real-statistics.com/tests-normality-and-symmetry/statistical-tests-normality-symmetry/dagostino-pearson-test/ for breaking it down into several steps.\n",
    "\n",
    "Once we have the Omnibus statistic, we can use a right-tailed $\\chi^2$ test to see the probability that the distribution is not Normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4147865896824052"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note I add an underscore to variables where the name might conflict with an already used variable\n",
    "\n",
    "c = 3 * (n**2 + 27 * n - 70) * (n + 1) * (n + 3) / ((n - 2) * (n + 5) * (n + 7) * (n + 9))\n",
    "w2 = np.sqrt(2 * (c - 1)) - 1\n",
    "w = np.sqrt(w2)\n",
    "a = np.sqrt((w2 - 1)/2)\n",
    "b_ = 1/np.sqrt(np.log(w))\n",
    "u = a * skew * np.sqrt((n + 1) * (n + 3) / (6 * (n - 2)))\n",
    "zs = b_ * np.log(u + np.sqrt(u**2 + 1))\n",
    "\n",
    "d = np.sqrt((n + 1)**2 * (n + 3) * (n + 5)/(24 * n * (n - 2) * (n - 3)))\n",
    "e = (6 * (n**2 - 5 * n + 2)/((n + 7) * (n + 9))) * np.sqrt(6 * (n + 3) * (n + 5)/(n * (n - 2) * (n - 3)))\n",
    "f_ = 6 + (8 / e) * ((2 / e) + np.sqrt(1 + 4 / e**2))\n",
    "g = d * (kurt - 3 * (n - 1)/ (n + 1)) * np.sqrt(2 / (f_ - 4))\n",
    "v = (1 - 2 / f_)/(1 + g)\n",
    "r_ = 2 / (9 * f_)\n",
    "zk = (1 - r_ - v **(1 / 3))/np.sqrt(r)\n",
    "\n",
    "omni = zs**2 + zk **2\n",
    "omni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0012408397107606e-10"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "omni - omni_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81269995642447"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_omni = sp.stats.chi2.sf(omni, 2)\n",
    "p_omni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.132039486241638e-11"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "p_omni - p_omni_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other test of normality shown in the summary is the Jarque-Bera test. The JB test is defined as follows:\n",
    "\n",
    "$$\\text{JB} = \\frac{n}{6} \\text{Skewness}^2  + \\frac{(\\text{Kurtosis} - 3)^2}{4} \\sim \\chi^2_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20402545915517234"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb = n/6 * (skew**2 + (kurt - 3)**2/4)\n",
    "jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.828807660864129e-10"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "jb - jb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9030180565573004"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_jb = sp.stats.chi2.sf(jb, 2)\n",
    "p_jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.25722823449837e-11"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "p_jb - p_jb_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top metric of the bottom table is the Durbin-Watson statistic. It measures autocorrelation in the residuals, which would violate the assumption of homoskedasticity (constant variance). A value of 2 means that there is no autocorrelation, 0-2 means negative autocorrelation, and 2-4 means positive autocorrelation. This is test is considered a bit outdated and is rarely used. \n",
    "\n",
    "$$\\text{DW} = \\frac{\\sum_{i = 2}^n (r_i - r_{i - 1})^2}{\\text{SSE}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789642114989123"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw = (np.diff(resid)**2).sum()/sse\n",
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9186874311571955e-12"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and let's compare to sm\n",
    "dw - dw_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last metric on the summary table is the Condition Number. This is actually not related to the residuals, so it kind of doesn't belong. It measures the degree to which the parameters of the model are intercollinear. This requires computing the eigenvalues of the $(X^\\top X)$ matrix we used to compute the coefficient estimates and their standard errors. \n",
    "\n",
    "Let $\\lambda_{max}$ and $\\lambda_{min}$ be the maximum and minimum eigenvalues of $X^\\top X$, respectively:\n",
    "\n",
    "$$\\text{Condition Number} = \\sqrt{\\frac{\\lambda_{max}}{\\lambda_{min}}}$$\n",
    "\n",
    "*Note: There are some issues with the implementation of condition number in statsmodels, as it does not normalize or center the X values and includes the constant which can cause an artificially high condition number. I include it for completelness, but I won't get into it. I also do not include it in the Excel and Sheets version of this because I do not know a convenient way to compute eigenvalues in spreadsheets using just built-in formulas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860663.3059171436"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig = np.linalg.eigvalsh(X.T @ X)\n",
    "cn = np.sqrt(max(eig)/min(eig))\n",
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_51451_row0_col0, #T_51451_row0_col2, #T_51451_row1_col0, #T_51451_row1_col2, #T_51451_row2_col0, #T_51451_row2_col2, #T_51451_row3_col0, #T_51451_row3_col2, #T_51451_row4_col0, #T_51451_row4_col2, #T_51451_row5_col0, #T_51451_row5_col2, #T_51451_row6_col0, #T_51451_row6_col2, #T_51451_row7_col0, #T_51451_row7_col2, #T_51451_row8_col0, #T_51451_row8_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_51451\">\n",
       "  <caption>OLS Regression Results</caption>\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row0_col0\" class=\"data row0 col0\" >Dep. Variable:</td>\n",
       "      <td id=\"T_51451_row0_col1\" class=\"data row0 col1\" >unemp</td>\n",
       "      <td id=\"T_51451_row0_col2\" class=\"data row0 col2\" >R-squared:</td>\n",
       "      <td id=\"T_51451_row0_col3\" class=\"data row0 col3\" >0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row1_col0\" class=\"data row1 col0\" >Model:</td>\n",
       "      <td id=\"T_51451_row1_col1\" class=\"data row1 col1\" >OLS</td>\n",
       "      <td id=\"T_51451_row1_col2\" class=\"data row1 col2\" >Adj. R-squared:</td>\n",
       "      <td id=\"T_51451_row1_col3\" class=\"data row1 col3\" >0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row2_col0\" class=\"data row2 col0\" >Method:</td>\n",
       "      <td id=\"T_51451_row2_col1\" class=\"data row2 col1\" >Least Squares</td>\n",
       "      <td id=\"T_51451_row2_col2\" class=\"data row2 col2\" >F-statistic:</td>\n",
       "      <td id=\"T_51451_row2_col3\" class=\"data row2 col3\" >197.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row3_col0\" class=\"data row3 col0\" >Date:</td>\n",
       "      <td id=\"T_51451_row3_col1\" class=\"data row3 col1\" >Thu, 18 May, 2023</td>\n",
       "      <td id=\"T_51451_row3_col2\" class=\"data row3 col2\" >Prob (F-statistic):</td>\n",
       "      <td id=\"T_51451_row3_col3\" class=\"data row3 col3\" >6.21e-85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row4_col0\" class=\"data row4 col0\" >Time:</td>\n",
       "      <td id=\"T_51451_row4_col1\" class=\"data row4 col1\" >17:28:04</td>\n",
       "      <td id=\"T_51451_row4_col2\" class=\"data row4 col2\" >Log-Likelihood:</td>\n",
       "      <td id=\"T_51451_row4_col3\" class=\"data row4 col3\" >-151.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row5_col0\" class=\"data row5 col0\" >No. Observations:</td>\n",
       "      <td id=\"T_51451_row5_col1\" class=\"data row5 col1\" >203</td>\n",
       "      <td id=\"T_51451_row5_col2\" class=\"data row5 col2\" >AIC:</td>\n",
       "      <td id=\"T_51451_row5_col3\" class=\"data row5 col3\" >319.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row6_col0\" class=\"data row6 col0\" >DF Residuals:</td>\n",
       "      <td id=\"T_51451_row6_col1\" class=\"data row6 col1\" >195</td>\n",
       "      <td id=\"T_51451_row6_col2\" class=\"data row6 col2\" >BIC:</td>\n",
       "      <td id=\"T_51451_row6_col3\" class=\"data row6 col3\" >346.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row7_col0\" class=\"data row7 col0\" >DF Model:</td>\n",
       "      <td id=\"T_51451_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "      <td id=\"T_51451_row7_col2\" class=\"data row7 col2\" ></td>\n",
       "      <td id=\"T_51451_row7_col3\" class=\"data row7 col3\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row8_col0\" class=\"data row8 col0\" >Covariance Type:</td>\n",
       "      <td id=\"T_51451_row8_col1\" class=\"data row8 col1\" >nonrobust</td>\n",
       "      <td id=\"T_51451_row8_col2\" class=\"data row8 col2\" ></td>\n",
       "      <td id=\"T_51451_row8_col3\" class=\"data row8 col3\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2372c5bc100>"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt     \n",
    "now = dt.datetime.now()\n",
    "today = now.strftime('%a, %d %b, %Y')\n",
    "time = now.strftime('%H:%M:%S')\n",
    "\n",
    "t1l = [('Dep. Variable:', y.name), \n",
    "        ('Model:', 'OLS'),\n",
    "        ('Method:', 'Least Squares'),\n",
    "        ('Date:', today),\n",
    "        ('Time:', time),\n",
    "        ('No. Observations:', n),\n",
    "        ('DF Residuals:', dfr),\n",
    "        ('DF Model:', dfm),\n",
    "        ('Covariance Type:', 'nonrobust')]\n",
    "\n",
    "t1r = [('R-squared:', r2), \n",
    "        ('Adj. R-squared:', r2_adj),\n",
    "        ('F-statistic:', f),\n",
    "        ('Prob (F-statistic):', p_f),\n",
    "        ('Log-Likelihood:', l),\n",
    "        ('AIC:', aic),\n",
    "        ('BIC:', bic),\n",
    "        ('', ''),\n",
    "        ('', '')]\n",
    "\n",
    "(t1c0, t1c1), (t1c2, t1c3) = (zip(*t1l), zip(*t1r))\n",
    "t1 = pd.DataFrame(zip(t1c0, t1c1, t1c2, t1c3)).style\\\n",
    "    .set_caption(\"OLS Regression Results\")\\\n",
    "    .hide(axis = 'index').hide(axis = 'columns')\\\n",
    "    .applymap(lambda x: \"font-weight: bold\", subset = [0, 2])\\\n",
    "    .format(precision=3)\\\n",
    "    .format(precision=1, subset = ([2, 5, 6], 3))\\\n",
    "    .format(\"{:.2e}\", subset = (3, 3))\n",
    "\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050000000000000044"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.025'"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"[{:0.3}\".format(alpha/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected '}' before end of string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[670], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat((pd\u001b[38;5;241m.\u001b[39mDataFrame([[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoef\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd err\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP>|t|\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m[:0.3}\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m[:0.3}\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)]]), \n\u001b[0;32m      2\u001b[0m                 pd\u001b[38;5;241m.\u001b[39mconcat((b, se, t, p, lb, ub), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)))\\\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mset_axis([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(b\u001b[38;5;241m.\u001b[39mindex), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mstyle\\\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mhide(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\\\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, subset \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m])\\\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfont-weight: bold\u001b[39m\u001b[38;5;124m\"\u001b[39m, subset \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m6\u001b[39m)))\n\u001b[0;32m      8\u001b[0m t2\n",
      "\u001b[1;31mValueError\u001b[0m: expected '}' before end of string"
     ]
    }
   ],
   "source": [
    "t2 = pd.concat((pd.DataFrame([['coef', 'std err', 't', 'P>|t|', \"{[:0.3}\".format(alpha/2), \"{[:0.3}\".format(1 - alpha/2)]]), \n",
    "                pd.concat((b, se, t, p, lb, ub), axis = 1, ignore_index = True)))\\\n",
    "    .set_axis([''] + list(b.index), axis = 0).style\\\n",
    "    .hide(axis = 'columns')\\\n",
    "    .format(precision=3)\\\n",
    "    .format(precision=4, subset = [0])\\\n",
    "    .applymap(lambda x: \"font-weight: bold\", subset = ('', slice(6)))\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8ee1f_row0_col0, #T_8ee1f_row0_col2, #T_8ee1f_row1_col0, #T_8ee1f_row1_col2, #T_8ee1f_row2_col0, #T_8ee1f_row2_col2, #T_8ee1f_row3_col0, #T_8ee1f_row3_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8ee1f\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row0_col0\" class=\"data row0 col0\" >Omnibus:</td>\n",
       "      <td id=\"T_8ee1f_row0_col1\" class=\"data row0 col1\" >0.415</td>\n",
       "      <td id=\"T_8ee1f_row0_col2\" class=\"data row0 col2\" >Durbin-Watson:</td>\n",
       "      <td id=\"T_8ee1f_row0_col3\" class=\"data row0 col3\" >0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row1_col0\" class=\"data row1 col0\" >Prob(Omnibus):</td>\n",
       "      <td id=\"T_8ee1f_row1_col1\" class=\"data row1 col1\" >0.813</td>\n",
       "      <td id=\"T_8ee1f_row1_col2\" class=\"data row1 col2\" >Jarque-Bera (JB):</td>\n",
       "      <td id=\"T_8ee1f_row1_col3\" class=\"data row1 col3\" >0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row2_col0\" class=\"data row2 col0\" >Skew:</td>\n",
       "      <td id=\"T_8ee1f_row2_col1\" class=\"data row2 col1\" >0.057</td>\n",
       "      <td id=\"T_8ee1f_row2_col2\" class=\"data row2 col2\" >Prob(JB):</td>\n",
       "      <td id=\"T_8ee1f_row2_col3\" class=\"data row2 col3\" >0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row3_col0\" class=\"data row3 col0\" >Kurtosis:</td>\n",
       "      <td id=\"T_8ee1f_row3_col1\" class=\"data row3 col1\" >3.106</td>\n",
       "      <td id=\"T_8ee1f_row3_col2\" class=\"data row3 col2\" >Cond. No.:</td>\n",
       "      <td id=\"T_8ee1f_row3_col3\" class=\"data row3 col3\" >8.61e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2372ccb4fa0>"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3l = [('Omnibus:', omni), \n",
    "       ('Prob(Omnibus):', p_omni),\n",
    "       ('Skew:', skew),\n",
    "       ('Kurtosis:', kurt)]\n",
    "\n",
    "t3r = [('Durbin-Watson:', dw), \n",
    "       ('Jarque-Bera (JB):', jb),\n",
    "       ('Prob(JB):', p_jb),\n",
    "       ('Cond. No.:', cn)]\n",
    "\n",
    "(t3c0, t3c1), (t3c2, t3c3) = (zip(*t3l), zip(*t3r))\n",
    "t3 = pd.DataFrame(zip(t3c0, t3c1, t3c2, t3c3)).style\\\n",
    "    .hide(axis = 'index').hide(axis = 'columns')\\\n",
    "    .applymap(lambda x: \"font-weight: bold\", subset = [0, 2])\\\n",
    "    .format(precision=3)\\\n",
    "    .format(\"{:.2e}\", subset = (3, 3))\n",
    "\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_51451_row0_col0, #T_51451_row0_col2, #T_51451_row1_col0, #T_51451_row1_col2, #T_51451_row2_col0, #T_51451_row2_col2, #T_51451_row3_col0, #T_51451_row3_col2, #T_51451_row4_col0, #T_51451_row4_col2, #T_51451_row5_col0, #T_51451_row5_col2, #T_51451_row6_col0, #T_51451_row6_col2, #T_51451_row7_col0, #T_51451_row7_col2, #T_51451_row8_col0, #T_51451_row8_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_51451\">\n",
       "  <caption>OLS Regression Results</caption>\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row0_col0\" class=\"data row0 col0\" >Dep. Variable:</td>\n",
       "      <td id=\"T_51451_row0_col1\" class=\"data row0 col1\" >unemp</td>\n",
       "      <td id=\"T_51451_row0_col2\" class=\"data row0 col2\" >R-squared:</td>\n",
       "      <td id=\"T_51451_row0_col3\" class=\"data row0 col3\" >0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row1_col0\" class=\"data row1 col0\" >Model:</td>\n",
       "      <td id=\"T_51451_row1_col1\" class=\"data row1 col1\" >OLS</td>\n",
       "      <td id=\"T_51451_row1_col2\" class=\"data row1 col2\" >Adj. R-squared:</td>\n",
       "      <td id=\"T_51451_row1_col3\" class=\"data row1 col3\" >0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row2_col0\" class=\"data row2 col0\" >Method:</td>\n",
       "      <td id=\"T_51451_row2_col1\" class=\"data row2 col1\" >Least Squares</td>\n",
       "      <td id=\"T_51451_row2_col2\" class=\"data row2 col2\" >F-statistic:</td>\n",
       "      <td id=\"T_51451_row2_col3\" class=\"data row2 col3\" >197.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row3_col0\" class=\"data row3 col0\" >Date:</td>\n",
       "      <td id=\"T_51451_row3_col1\" class=\"data row3 col1\" >Thu, 18 May, 2023</td>\n",
       "      <td id=\"T_51451_row3_col2\" class=\"data row3 col2\" >Prob (F-statistic):</td>\n",
       "      <td id=\"T_51451_row3_col3\" class=\"data row3 col3\" >6.21e-85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row4_col0\" class=\"data row4 col0\" >Time:</td>\n",
       "      <td id=\"T_51451_row4_col1\" class=\"data row4 col1\" >17:28:04</td>\n",
       "      <td id=\"T_51451_row4_col2\" class=\"data row4 col2\" >Log-Likelihood:</td>\n",
       "      <td id=\"T_51451_row4_col3\" class=\"data row4 col3\" >-151.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row5_col0\" class=\"data row5 col0\" >No. Observations:</td>\n",
       "      <td id=\"T_51451_row5_col1\" class=\"data row5 col1\" >203</td>\n",
       "      <td id=\"T_51451_row5_col2\" class=\"data row5 col2\" >AIC:</td>\n",
       "      <td id=\"T_51451_row5_col3\" class=\"data row5 col3\" >319.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row6_col0\" class=\"data row6 col0\" >DF Residuals:</td>\n",
       "      <td id=\"T_51451_row6_col1\" class=\"data row6 col1\" >195</td>\n",
       "      <td id=\"T_51451_row6_col2\" class=\"data row6 col2\" >BIC:</td>\n",
       "      <td id=\"T_51451_row6_col3\" class=\"data row6 col3\" >346.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row7_col0\" class=\"data row7 col0\" >DF Model:</td>\n",
       "      <td id=\"T_51451_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "      <td id=\"T_51451_row7_col2\" class=\"data row7 col2\" ></td>\n",
       "      <td id=\"T_51451_row7_col3\" class=\"data row7 col3\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_51451_row8_col0\" class=\"data row8 col0\" >Covariance Type:</td>\n",
       "      <td id=\"T_51451_row8_col1\" class=\"data row8 col1\" >nonrobust</td>\n",
       "      <td id=\"T_51451_row8_col2\" class=\"data row8 col2\" ></td>\n",
       "      <td id=\"T_51451_row8_col3\" class=\"data row8 col3\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2372c5bc100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bbc14_row0_col0, #T_bbc14_row0_col1, #T_bbc14_row0_col2, #T_bbc14_row0_col3, #T_bbc14_row0_col4, #T_bbc14_row0_col5 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bbc14\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row0\" class=\"row_heading level0 row0\" ></th>\n",
       "      <td id=\"T_bbc14_row0_col0\" class=\"data row0 col0\" >coef</td>\n",
       "      <td id=\"T_bbc14_row0_col1\" class=\"data row0 col1\" >std err</td>\n",
       "      <td id=\"T_bbc14_row0_col2\" class=\"data row0 col2\" >t</td>\n",
       "      <td id=\"T_bbc14_row0_col3\" class=\"data row0 col3\" >P>|t|</td>\n",
       "      <td id=\"T_bbc14_row0_col4\" class=\"data row0 col4\" >[0.025</td>\n",
       "      <td id=\"T_bbc14_row0_col5\" class=\"data row0 col5\" >0.975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row1\" class=\"row_heading level0 row1\" >const</th>\n",
       "      <td id=\"T_bbc14_row1_col0\" class=\"data row1 col0\" >-17.5391</td>\n",
       "      <td id=\"T_bbc14_row1_col1\" class=\"data row1 col1\" >2.806</td>\n",
       "      <td id=\"T_bbc14_row1_col2\" class=\"data row1 col2\" >-6.250</td>\n",
       "      <td id=\"T_bbc14_row1_col3\" class=\"data row1 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row1_col4\" class=\"data row1 col4\" >-23.074</td>\n",
       "      <td id=\"T_bbc14_row1_col5\" class=\"data row1 col5\" >-12.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row2\" class=\"row_heading level0 row2\" >realgdp</th>\n",
       "      <td id=\"T_bbc14_row2_col0\" class=\"data row2 col0\" >-0.0116</td>\n",
       "      <td id=\"T_bbc14_row2_col1\" class=\"data row2 col1\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row2_col2\" class=\"data row2 col2\" >-27.105</td>\n",
       "      <td id=\"T_bbc14_row2_col3\" class=\"data row2 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row2_col4\" class=\"data row2 col4\" >-0.012</td>\n",
       "      <td id=\"T_bbc14_row2_col5\" class=\"data row2 col5\" >-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row3\" class=\"row_heading level0 row3\" >realcons</th>\n",
       "      <td id=\"T_bbc14_row3_col0\" class=\"data row3 col0\" >0.0087</td>\n",
       "      <td id=\"T_bbc14_row3_col1\" class=\"data row3 col1\" >0.001</td>\n",
       "      <td id=\"T_bbc14_row3_col2\" class=\"data row3 col2\" >10.055</td>\n",
       "      <td id=\"T_bbc14_row3_col3\" class=\"data row3 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row3_col4\" class=\"data row3 col4\" >0.007</td>\n",
       "      <td id=\"T_bbc14_row3_col5\" class=\"data row3 col5\" >0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row4\" class=\"row_heading level0 row4\" >realgovt</th>\n",
       "      <td id=\"T_bbc14_row4_col0\" class=\"data row4 col0\" >-0.0030</td>\n",
       "      <td id=\"T_bbc14_row4_col1\" class=\"data row4 col1\" >0.001</td>\n",
       "      <td id=\"T_bbc14_row4_col2\" class=\"data row4 col2\" >-4.824</td>\n",
       "      <td id=\"T_bbc14_row4_col3\" class=\"data row4 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row4_col4\" class=\"data row4 col4\" >-0.004</td>\n",
       "      <td id=\"T_bbc14_row4_col5\" class=\"data row4 col5\" >-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row5\" class=\"row_heading level0 row5\" >realdpi</th>\n",
       "      <td id=\"T_bbc14_row5_col0\" class=\"data row5 col0\" >0.0029</td>\n",
       "      <td id=\"T_bbc14_row5_col1\" class=\"data row5 col1\" >0.001</td>\n",
       "      <td id=\"T_bbc14_row5_col2\" class=\"data row5 col2\" >4.112</td>\n",
       "      <td id=\"T_bbc14_row5_col3\" class=\"data row5 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row5_col4\" class=\"data row5 col4\" >0.002</td>\n",
       "      <td id=\"T_bbc14_row5_col5\" class=\"data row5 col5\" >0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row6\" class=\"row_heading level0 row6\" >cpi</th>\n",
       "      <td id=\"T_bbc14_row6_col0\" class=\"data row6 col0\" >0.0799</td>\n",
       "      <td id=\"T_bbc14_row6_col1\" class=\"data row6 col1\" >0.006</td>\n",
       "      <td id=\"T_bbc14_row6_col2\" class=\"data row6 col2\" >13.065</td>\n",
       "      <td id=\"T_bbc14_row6_col3\" class=\"data row6 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row6_col4\" class=\"data row6 col4\" >0.068</td>\n",
       "      <td id=\"T_bbc14_row6_col5\" class=\"data row6 col5\" >0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row7\" class=\"row_heading level0 row7\" >m1</th>\n",
       "      <td id=\"T_bbc14_row7_col0\" class=\"data row7 col0\" >-0.0030</td>\n",
       "      <td id=\"T_bbc14_row7_col1\" class=\"data row7 col1\" >0.001</td>\n",
       "      <td id=\"T_bbc14_row7_col2\" class=\"data row7 col2\" >-4.945</td>\n",
       "      <td id=\"T_bbc14_row7_col3\" class=\"data row7 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row7_col4\" class=\"data row7 col4\" >-0.004</td>\n",
       "      <td id=\"T_bbc14_row7_col5\" class=\"data row7 col5\" >-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbc14_level0_row8\" class=\"row_heading level0 row8\" >pop</th>\n",
       "      <td id=\"T_bbc14_row8_col0\" class=\"data row8 col0\" >0.1907</td>\n",
       "      <td id=\"T_bbc14_row8_col1\" class=\"data row8 col1\" >0.018</td>\n",
       "      <td id=\"T_bbc14_row8_col2\" class=\"data row8 col2\" >10.646</td>\n",
       "      <td id=\"T_bbc14_row8_col3\" class=\"data row8 col3\" >0.000</td>\n",
       "      <td id=\"T_bbc14_row8_col4\" class=\"data row8 col4\" >0.155</td>\n",
       "      <td id=\"T_bbc14_row8_col5\" class=\"data row8 col5\" >0.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2372cc3e790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8ee1f_row0_col0, #T_8ee1f_row0_col2, #T_8ee1f_row1_col0, #T_8ee1f_row1_col2, #T_8ee1f_row2_col0, #T_8ee1f_row2_col2, #T_8ee1f_row3_col0, #T_8ee1f_row3_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8ee1f\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row0_col0\" class=\"data row0 col0\" >Omnibus:</td>\n",
       "      <td id=\"T_8ee1f_row0_col1\" class=\"data row0 col1\" >0.415</td>\n",
       "      <td id=\"T_8ee1f_row0_col2\" class=\"data row0 col2\" >Durbin-Watson:</td>\n",
       "      <td id=\"T_8ee1f_row0_col3\" class=\"data row0 col3\" >0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row1_col0\" class=\"data row1 col0\" >Prob(Omnibus):</td>\n",
       "      <td id=\"T_8ee1f_row1_col1\" class=\"data row1 col1\" >0.813</td>\n",
       "      <td id=\"T_8ee1f_row1_col2\" class=\"data row1 col2\" >Jarque-Bera (JB):</td>\n",
       "      <td id=\"T_8ee1f_row1_col3\" class=\"data row1 col3\" >0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row2_col0\" class=\"data row2 col0\" >Skew:</td>\n",
       "      <td id=\"T_8ee1f_row2_col1\" class=\"data row2 col1\" >0.057</td>\n",
       "      <td id=\"T_8ee1f_row2_col2\" class=\"data row2 col2\" >Prob(JB):</td>\n",
       "      <td id=\"T_8ee1f_row2_col3\" class=\"data row2 col3\" >0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8ee1f_row3_col0\" class=\"data row3 col0\" >Kurtosis:</td>\n",
       "      <td id=\"T_8ee1f_row3_col1\" class=\"data row3 col1\" >3.106</td>\n",
       "      <td id=\"T_8ee1f_row3_col2\" class=\"data row3 col2\" >Cond. No.:</td>\n",
       "      <td id=\"T_8ee1f_row3_col3\" class=\"data row3 col3\" >8.61e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2372ccb4fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(t1, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>unemp</td>      <th>  R-squared:         </th> <td>   0.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   197.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 May 2023</td> <th>  Prob (F-statistic):</th> <td>6.21e-85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:27:17</td>     <th>  Log-Likelihood:    </th> <td> -151.94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   203</td>      <th>  AIC:               </th> <td>   319.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   195</td>      <th>  BIC:               </th> <td>   346.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>  -17.5391</td> <td>    2.806</td> <td>   -6.250</td> <td> 0.000</td> <td>  -23.074</td> <td>  -12.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realgdp</th>  <td>   -0.0116</td> <td>    0.000</td> <td>  -27.105</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realcons</th> <td>    0.0087</td> <td>    0.001</td> <td>   10.055</td> <td> 0.000</td> <td>    0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realgovt</th> <td>   -0.0030</td> <td>    0.001</td> <td>   -4.824</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>realdpi</th>  <td>    0.0029</td> <td>    0.001</td> <td>    4.112</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cpi</th>      <td>    0.0799</td> <td>    0.006</td> <td>   13.065</td> <td> 0.000</td> <td>    0.068</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m1</th>       <td>   -0.0030</td> <td>    0.001</td> <td>   -4.945</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>      <td>    0.1907</td> <td>    0.018</td> <td>   10.646</td> <td> 0.000</td> <td>    0.155</td> <td>    0.226</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.415</td> <th>  Durbin-Watson:     </th> <td>   0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.813</td> <th>  Jarque-Bera (JB):  </th> <td>   0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.057</td> <th>  Prob(JB):          </th> <td>   0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.106</td> <th>  Cond. No.          </th> <td>8.61e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.61e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  unemp   R-squared:                       0.876\n",
       "Model:                            OLS   Adj. R-squared:                  0.872\n",
       "Method:                 Least Squares   F-statistic:                     197.6\n",
       "Date:                Thu, 18 May 2023   Prob (F-statistic):           6.21e-85\n",
       "Time:                        15:27:17   Log-Likelihood:                -151.94\n",
       "No. Observations:                 203   AIC:                             319.9\n",
       "Df Residuals:                     195   BIC:                             346.4\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -17.5391      2.806     -6.250      0.000     -23.074     -12.004\n",
       "realgdp       -0.0116      0.000    -27.105      0.000      -0.012      -0.011\n",
       "realcons       0.0087      0.001     10.055      0.000       0.007       0.010\n",
       "realgovt      -0.0030      0.001     -4.824      0.000      -0.004      -0.002\n",
       "realdpi        0.0029      0.001      4.112      0.000       0.002       0.004\n",
       "cpi            0.0799      0.006     13.065      0.000       0.068       0.092\n",
       "m1            -0.0030      0.001     -4.945      0.000      -0.004      -0.002\n",
       "pop            0.1907      0.018     10.646      0.000       0.155       0.226\n",
       "==============================================================================\n",
       "Omnibus:                        0.415   Durbin-Watson:                   0.779\n",
       "Prob(Omnibus):                  0.813   Jarque-Bera (JB):                0.204\n",
       "Skew:                           0.057   Prob(JB):                        0.903\n",
       "Kurtosis:                       3.106   Cond. No.                     8.61e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.61e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
